{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"YacKhSCw9dDD"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4010,"status":"ok","timestamp":1732174188714,"user":{"displayName":"Durga Sree Priya Vattikonda","userId":"12269154942002657306"},"user_tz":-330},"id":"7m0OWyDfTARH","outputId":"738c3934-6e08-48c6-9d46-5a92668252ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"uehOHoAZ4GSQ","outputId":"e46d565e-ab50-4876-ae4c-2c5f2c1184bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-2-102f650882ce>:58: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  taxonomy_deviant.iloc[:, 1:] = taxonomy_deviant.iloc[:, 1:].apply(lambda x: x.str.strip('%').astype(float))\n","<ipython-input-2-102f650882ce>:73: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  taxonomy_deviant[\"set_class\"] = class_list\n","<ipython-input-2-102f650882ce>:73: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  taxonomy_deviant[\"set_class\"] = class_list\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - loss: 0.0047 - mae: 0.0423 - val_loss: 0.0014 - val_mae: 0.0381\n","Epoch 2/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - loss: 0.0044 - mae: 0.0476 - val_loss: 0.0013 - val_mae: 0.0363\n","Epoch 3/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 6.2481e-04 - mae: 0.0201 - val_loss: 7.9276e-04 - val_mae: 0.0282\n","Epoch 4/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 5.5603e-04 - mae: 0.0195 - val_loss: 4.8620e-04 - val_mae: 0.0220\n","Epoch 5/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - loss: 0.0013 - mae: 0.0247 - val_loss: 4.8763e-04 - val_mae: 0.0221\n","Epoch 6/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0022 - mae: 0.0315 - val_loss: 6.6014e-04 - val_mae: 0.0257\n","Epoch 7/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0018 - mae: 0.0309 - val_loss: 0.0010 - val_mae: 0.0319\n","Epoch 8/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0139 - mae: 0.0895 - val_loss: 0.0011 - val_mae: 0.0338\n","Epoch 9/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - loss: 6.7428e-04 - mae: 0.0198 - val_loss: 0.0013 - val_mae: 0.0365\n","Epoch 10/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0059 - mae: 0.0645 - val_loss: 0.0014 - val_mae: 0.0373\n","Epoch 11/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - loss: 2.8145e-04 - mae: 0.0133 - val_loss: 0.0015 - val_mae: 0.0385\n","Epoch 12/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0119 - mae: 0.0905 - val_loss: 0.0014 - val_mae: 0.0377\n","Epoch 13/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - loss: 0.0017 - mae: 0.0350 - val_loss: 0.0014 - val_mae: 0.0380\n","Epoch 14/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0032 - mae: 0.0462 - val_loss: 0.0014 - val_mae: 0.0370\n","Epoch 15/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0033 - mae: 0.0439 - val_loss: 0.0012 - val_mae: 0.0345\n","Epoch 16/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 2.9152e-04 - mae: 0.0159 - val_loss: 0.0011 - val_mae: 0.0330\n","Epoch 17/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0013 - mae: 0.0297 - val_loss: 9.6612e-04 - val_mae: 0.0311\n","Epoch 18/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 5.6383e-04 - mae: 0.0209 - val_loss: 8.8808e-04 - val_mae: 0.0298\n","Epoch 19/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 8.3878e-04 - val_mae: 0.0290\n","Epoch 20/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 7.9553e-04 - mae: 0.0253 - val_loss: 7.3655e-04 - val_mae: 0.0271\n","Epoch 21/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0042 - mae: 0.0424 - val_loss: 5.8297e-04 - val_mae: 0.0241\n","Epoch 22/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0110 - mae: 0.0643 - val_loss: 3.4976e-04 - val_mae: 0.0187\n","Epoch 23/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 2.1264e-04 - val_mae: 0.0146\n","Epoch 24/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 7.9830e-04 - mae: 0.0187 - val_loss: 1.2941e-04 - val_mae: 0.0114\n","Epoch 25/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 1.1921e-04 - mae: 0.0105 - val_loss: 7.8122e-05 - val_mae: 0.0088\n","Epoch 26/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 0.0014 - mae: 0.0290 - val_loss: 4.6555e-05 - val_mae: 0.0068\n","Epoch 27/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 1.9497e-05 - val_mae: 0.0044\n","Epoch 28/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 7.9685e-04 - mae: 0.0235 - val_loss: 2.9965e-06 - val_mae: 0.0017\n","Epoch 29/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 2.4802e-04 - mae: 0.0122 - val_loss: 2.9966e-07 - val_mae: 5.4741e-04\n","Epoch 30/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.0050 - mae: 0.0574 - val_loss: 7.5147e-08 - val_mae: 2.7413e-04\n","Epoch 31/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0030 - mae: 0.0409 - val_loss: 7.4088e-07 - val_mae: 8.6074e-04\n","Epoch 32/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 5.5680e-06 - val_mae: 0.0024\n","Epoch 33/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 9.6971e-04 - mae: 0.0239 - val_loss: 2.4128e-05 - val_mae: 0.0049\n","Epoch 34/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 7.2496e-04 - mae: 0.0222 - val_loss: 4.8560e-05 - val_mae: 0.0070\n","Epoch 35/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - loss: 0.0022 - mae: 0.0301 - val_loss: 1.0064e-04 - val_mae: 0.0100\n","Epoch 36/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 2.8012e-04 - mae: 0.0105 - val_loss: 1.7309e-04 - val_mae: 0.0132\n","Epoch 37/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0015 - mae: 0.0311 - val_loss: 2.1850e-04 - val_mae: 0.0148\n","Epoch 38/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 2.5798e-04 - val_mae: 0.0161\n","Epoch 39/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 7.5314e-04 - mae: 0.0170 - val_loss: 2.7619e-04 - val_mae: 0.0166\n","Epoch 40/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0045 - mae: 0.0414 - val_loss: 3.6063e-04 - val_mae: 0.0190\n","Epoch 41/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 7.7826e-04 - mae: 0.0228 - val_loss: 4.2663e-04 - val_mae: 0.0207\n","Epoch 42/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.0017 - mae: 0.0304 - val_loss: 5.6930e-04 - val_mae: 0.0239\n","Epoch 43/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0048 - mae: 0.0559 - val_loss: 6.1504e-04 - val_mae: 0.0248\n","Epoch 44/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0034 - mae: 0.0449 - val_loss: 5.7943e-04 - val_mae: 0.0241\n","Epoch 45/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0016 - mae: 0.0254 - val_loss: 4.7994e-04 - val_mae: 0.0219\n","Epoch 46/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.9021e-04 - mae: 0.0106 - val_loss: 3.8427e-04 - val_mae: 0.0196\n","Epoch 47/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 2.9195e-04 - val_mae: 0.0171\n","Epoch 48/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0016 - mae: 0.0250 - val_loss: 1.9483e-04 - val_mae: 0.0140\n","Epoch 49/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 1.0923e-04 - mae: 0.0069 - val_loss: 1.2463e-04 - val_mae: 0.0112\n","Epoch 50/50\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 0.0031 - mae: 0.0352 - val_loss: 5.5343e-05 - val_mae: 0.0074\n","Test Mean Absolute Error: 0.01\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n","Sample predictions: [-0.0102517]\n","Available Nutrients:\n","0: Trp\n","1: His\n","2: Pro\n","3: Leu\n","4: Arg\n","5: Ile_Val\n","6: Tyr\n","7: Phe\n","8: Ser\n","9: Met\n","10: Cys\n","11: Thr\n","12: Lys\n","13: Gln\n","14: Chor\n","15: Glu\n","16: Asn\n","17: Asp\n","18: Gly\n","19: Thr_D\n","20: Trp_D\n","21: His_D\n","22: Pro_D\n","23: Met_D\n","24: Lys_D\n","25: Mal\n","26: Fru\n","27: Glc\n","28: (Mal)n\n","29: Gal\n","30: GlcNAc\n","31: Bgl\n","32: Scr\n","33: Rib\n","34: NANA\n","35: Man\n","36: XOS\n","37: FOS\n","38: Lac\n","39: Xyl\n","40: (Man)n\n","41: GlcA\n","42: Chb\n","43: Ara\n","44: Tre\n","45: (Rha)n\n","46: Lnb\n","47: (GalA)n\n","48: GalA\n","49: Fuc\n","50: aAOS\n","51: Aga\n","52: GOS\n","53: Rha\n","54: Ino\n","55: Mtl\n","56: a(Xyl)n\n","57: Srl\n","58: Gnt\n","59: (Fuc)n\n","60: MurNac\n","61: FruLys\n","62: Mel\n","63: Mannan\n","64: ManNAc\n","65: GalN\n","66: ddGlcA\n","67: Hyl\n","68: Gtl\n","69: PsiLys\n","70: (GlcA)n\n","71: GalNAc\n","72: Tag\n","73: GlcLys\n","74: Atl\n","75: All\n","76: Xtl\n","77: Rtl\n","78: Raf\n","79: FruAsp\n","80: bAOS\n","81: B1\n","82: B2\n","83: B3\n","84: B5\n","85: B6\n","86: B7\n","87: B9\n","88: B12\n","89: Q\n","90: Lipoate\n","91: K\n","Available Nutrients:\n","0: Trp\n","1: His\n","2: Pro\n","3: Leu\n","4: Arg\n","5: Ile_Val\n","6: Tyr\n","7: Phe\n","8: Ser\n","9: Met\n","10: Cys\n","11: Thr\n","12: Lys\n","13: Gln\n","14: Chor\n","15: Glu\n","16: Asn\n","17: Asp\n","18: Gly\n","19: Thr_D\n","20: Trp_D\n","21: His_D\n","22: Pro_D\n","23: Met_D\n","24: Lys_D\n","25: Mal\n","26: Fru\n","27: Glc\n","28: (Mal)n\n","29: Gal\n","30: GlcNAc\n","31: Bgl\n","32: Scr\n","33: Rib\n","34: NANA\n","35: Man\n","36: XOS\n","37: FOS\n","38: Lac\n","39: Xyl\n","40: (Man)n\n","41: GlcA\n","42: Chb\n","43: Ara\n","44: Tre\n","45: (Rha)n\n","46: Lnb\n","47: (GalA)n\n","48: GalA\n","49: Fuc\n","50: aAOS\n","51: Aga\n","52: GOS\n","53: Rha\n","54: Ino\n","55: Mtl\n","56: a(Xyl)n\n","57: Srl\n","58: Gnt\n","59: (Fuc)n\n","60: MurNac\n","61: FruLys\n","62: Mel\n","63: Mannan\n","64: ManNAc\n","65: GalN\n","66: ddGlcA\n","67: Hyl\n","68: Gtl\n","69: PsiLys\n","70: (GlcA)n\n","71: GalNAc\n","72: Tag\n","73: GlcLys\n","74: Atl\n","75: All\n","76: Xtl\n","77: Rtl\n","78: Raf\n","79: FruAsp\n","80: bAOS\n","81: B1\n","82: B2\n","83: B3\n","84: B5\n","85: B6\n","86: B7\n","87: B9\n","88: B12\n","89: Q\n","90: Lipoate\n","91: K\n"]}],"source":["# Importing necessary libraries\n","import pandas as pd\n","import numpy as np\n","import os\n","import random\n","from google.colab import drive\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Define the directory where all files are located\n","base_dir = \"/content/drive/My Drive/durga_project\"\n","\n","# Load metadata\n","metadata_path = os.path.join(base_dir, \"metadata.csv\")\n","metadata = pd.read_csv(metadata_path)\n","\n","# Filters for 'NORMAL' and 'DEVIANT' groups\n","filter1 = metadata[\"group\"] == \"NORMAL\"\n","filter2 = metadata[\"group\"] == \"DEVIANT\"\n","\n","normal_sample_ids = metadata[filter1][\"sample-id\"].to_numpy()\n","normal_sample_ids = np.insert(normal_sample_ids, 0, 'taxonomy')\n","\n","# Load taxonomy data\n","taxonomy_path = os.path.join(base_dir, \"taxonomy_400.csv\")\n","taxonomy = pd.read_csv(taxonomy_path)\n","\n","# Process taxonomy for NORMAL samples\n","taxonomy_normal = taxonomy[[\"taxonomy\"] + list(normal_sample_ids[1:])]\n","taxonomy_normal.set_index(\"taxonomy\", inplace=True)\n","\n","# Save taxonomy range\n","taxonomy_range = list(taxonomy_normal.index)\n","\n","# Calculate population-averaged relative abundances\n","reference_data = []\n","for taxon in taxonomy_range:\n","    ref_data = taxonomy_normal.loc[taxon].str.strip('%').astype(float)\n","    ref_mean = np.mean(ref_data)\n","    ref_std = np.std(ref_data)\n","    ref_max = ref_mean + ref_std\n","    ref_min = ref_mean - ref_std\n","    reference_data.append((taxon, ref_mean, ref_std, ref_max, ref_min))\n","\n","normal_parameters = pd.DataFrame(reference_data, columns=[\"taxonomy\", \"mean\", \"std\", \"max\", \"min\"])\n","normal_parameters.set_index(\"taxonomy\", inplace=True)\n","\n","# Process taxonomy for DEVIANT samples\n","deviant_sample_ids = metadata[filter2][\"sample-id\"].to_numpy()\n","deviant_sample_ids = np.insert(deviant_sample_ids, 0, 'taxonomy')\n","\n","taxonomy_deviant = taxonomy[[\"taxonomy\"] + list(deviant_sample_ids[1:])]\n","taxonomy_deviant.iloc[:, 1:] = taxonomy_deviant.iloc[:, 1:].apply(lambda x: x.str.strip('%').astype(float))\n","taxonomy_deviant.set_index(\"taxonomy\", inplace=True)\n","\n","# Categorize taxons into 'U', 'O', or 'N'\n","class_list = []\n","for taxon in taxonomy_range:\n","    ref_parameters = normal_parameters.loc[taxon]\n","    test_val = taxonomy_deviant.loc[taxon].mean()\n","    if test_val < ref_parameters[\"min\"]:\n","        class_list.append(\"U\")\n","    elif test_val > ref_parameters[\"max\"]:\n","        class_list.append(\"O\")\n","    else:\n","        class_list.append(\"N\")\n","\n","taxonomy_deviant[\"set_class\"] = class_list\n","\n","# Load nutrient impact matrices\n","nim_aminoacids_path = os.path.join(base_dir, \"nim-aminoacids_400.csv\")\n","nim_aminoacids = pd.read_csv(nim_aminoacids_path)\n","\n","nim_aminoacidsD_path = os.path.join(base_dir, \"nim-aminoacidsD_400.csv\")\n","nim_sugars_path = os.path.join(base_dir, \"nim-sugars_400.csv\")\n","nim_vitamins_path = os.path.join(base_dir, \"nim-vitamins_400.csv\")\n","\n","nim_aminoacidsD = pd.read_csv(nim_aminoacidsD_path)\n","nim_sugars = pd.read_csv(nim_sugars_path)\n","nim_vitamins = pd.read_csv(nim_vitamins_path)\n","\n","# Merge nutrient matrices\n","nim_total = nim_aminoacids.set_index('taxonomy')\n","nim_total = nim_total.join(nim_aminoacidsD.set_index('taxonomy'))\n","nim_total = nim_total.join(nim_sugars.set_index('taxonomy'))\n","nim_total = nim_total.join(nim_vitamins.set_index('taxonomy'))\n","\n","# Nutrient range\n","nutrients_range = list(nim_total.columns)\n","\n","# Categorize unbalanced taxons\n","dict_unbalanced_U = {}\n","dict_unbalanced_O = {}\n","\n","for taxon in taxonomy_range:\n","    if taxonomy_deviant.loc[taxon, \"set_class\"] == \"U\":\n","        dict_unbalanced_U[taxon] = nim_total.loc[taxon].values.tolist()\n","    elif taxonomy_deviant.loc[taxon, \"set_class\"] == \"O\":\n","        dict_unbalanced_O[taxon] = nim_total.loc[taxon].values.tolist()\n","\n","# Reward function\n","def reward(a, dict_unbalanced, list_indices, epsilon):\n","    temp_product = 1\n","    ref_nim_list = dict_unbalanced[a]\n","    for index in list_indices:\n","        temp_product *= (1 - ref_nim_list[index])\n","    return 1 if (1 - temp_product) >= epsilon else 0\n","\n","# Reward nutrient\n","def reward_nutrient(n, dict_unbalanced_O, dict_unbalanced_U, epsilon_O, epsilon_U):\n","    sum_U = sum(reward(b, dict_unbalanced_U, [n], epsilon_U) for b in dict_unbalanced_U)\n","    sum_O = sum(reward(a, dict_unbalanced_O, [n], epsilon_O) for a in dict_unbalanced_O)\n","    return sum_U - sum_O\n","\n","# Randomized algorithm\n","final_score_dict = {}\n","m_values = [5, 10, 15, 20, 25]\n","epsilon_O, epsilon_U = 0.9, 0.5\n","\n","for m in m_values:\n","    temp_max_length, temp_max_score = 0, -10000\n","    for _ in range(5000):  # Reduced iterations for runtime efficiency\n","        temp_score_dict = {}\n","        for j in range(1, m + 1):\n","            list_indices = random.sample(range(len(nutrients_range)), j)\n","            sum_U = sum(reward(b, dict_unbalanced_U, list_indices, epsilon_U) for b in dict_unbalanced_U)\n","            sum_O = sum(reward(a, dict_unbalanced_O, list_indices, epsilon_O) for a in dict_unbalanced_O)\n","            tempscore = sum_U - sum_O\n","            temp_score_dict[len(list_indices)] = tempscore\n","        key_max = max(temp_score_dict, key=temp_score_dict.get)\n","        score_max = temp_score_dict[key_max]\n","        if score_max > temp_max_score:\n","            temp_max_score = score_max\n","            temp_max_length = key_max\n","    final_score_dict[m] = [temp_max_length, temp_max_score]\n","\n","# Prepare data for deep learning\n","X = []\n","y = []\n","\n","for m, scores in final_score_dict.items():\n","    feature = [m] + scores\n","    target = scores[1]\n","    X.append(feature)\n","    y.append(target)\n","\n","X = np.array(X)\n","y = np.array(y)\n","\n","# Normalize features\n","scaler = MinMaxScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n","\n","# Deep learning model\n","model = Sequential([\n","    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n","    Dropout(0.3),\n","    Dense(32, activation='relu'),\n","    Dropout(0.3),\n","    Dense(16, activation='relu'),\n","    Dense(1, activation='linear')\n","])\n","\n","model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n","history = model.fit(X_train, y_train, epochs=50, batch_size=8, validation_split=0.1, verbose=1)\n","\n","# Evaluate and predict\n","loss, mae = model.evaluate(X_test, y_test, verbose=0)\n","print(f\"Test Mean Absolute Error: {mae:.2f}\")\n","\n","y_pred = model.predict(X_test)\n","print(\"Sample predictions:\", y_pred[:5].flatten())\n","# List all available nutrients\n","nutrients_range = list(nim_total.columns)\n","print(\"Available Nutrients:\")\n","for idx, nutrient in enumerate(nutrients_range):\n","    print(f\"{idx}: {nutrient}\")\n","\n","# Define thresholds for impact score evaluation\n","GOOD_THRESHOLD = 10\n","BAD_THRESHOLD = -10\n","\n","# Function to classify impact score\n","def evaluate_impact_score(score):\n","    if score > GOOD_THRESHOLD:\n","        return \"Good Impact\"\n","    elif score < BAD_THRESHOLD:\n","        return \"Bad Impact\"\n","    else:\n","        return \"Neutral Impact\"\n","\n","# Function to take input, predict, and evaluate\n","def predict_and_evaluate_nutrient_score():\n","    # List all available nutrients\n","    nutrients_range = list(nim_total.columns)\n","    print(\"Available Nutrients:\")\n","    for idx, nutrient in enumerate(nutrients_range):\n","        print(f\"{idx}: {nutrient}\")\n","\n","    # Prompt user to select nutrients by their index\n","    selected_indices = input(\"Enter the indices of selected nutrients (comma-separated): \")\n","    selected_indices = [int(i) for i in selected_indices.split(\",\")]\n","\n","    # Display the selected nutrients\n","    selected_nutrients = [nutrients_range[i] for i in selected_indices]\n","    print(f\"Selected Nutrients: {selected_nutrients}\")\n","\n","    # Prompt user for additional input values\n","    m = len(selected_indices)  # Automatically set m to the number of selected nutrients\n","    nutrient_combination_length = int(input(\"Enter the length of nutrient combination: \"))\n","    max_score = float(input(\"Enter the maximum nutrient score: \"))\n","\n","    # Prepare the input feature\n","    input_feature = np.array([[m, nutrient_combination_length, max_score]])\n","\n","    # Normalize the input feature using the scaler\n","    input_feature_scaled = scaler.transform(input_feature)\n","\n","    # Make prediction\n","    prediction = model.predict(input_feature_scaled)\n","    impact_score = prediction[0][0]\n","\n","    # Evaluate the impact score\n","    evaluation = evaluate_impact_score(impact_score)\n","\n","    print(f\"Predicted Nutrient Impact Score: {impact_score:.2f}\")\n","    print(f\"Impact Evaluation: {evaluation}\")\n","\n","# Call the function to get input, predict, and evaluate\n","predict_and_evaluate_nutrient_score()\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1dyrY9b3O7wH0JuWNSg0Sz6GM-BTknBGk","timestamp":1732014420302}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}